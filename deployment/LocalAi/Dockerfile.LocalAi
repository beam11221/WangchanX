FROM localai/localai:latest-aio-gpu-nvidia-cuda-12
COPY LLaMa3-8b-WangchanX-sft-Full.yaml /build/models
COPY bge-m3.yaml /build/models
